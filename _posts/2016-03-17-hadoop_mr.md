---
layout: post
title:  "hadoop MapReduce"
date:   2016-03-17 09:05:31
categories: hadoop
tags: hadoop
---

* content
{:toc}

## map 和 reduce

MapReduce 的工作过程分为两个阶段：map阶段和reduce阶段。

每个阶段都有键值对作为输入和输出。

程序员还具体定义两个函数: map函数和reduce函数

这里以统计单词数为例，来说明MapReduce的过程：

```python
输入文本为：
hello, world
hello, mouren
...

map阶段输入的是原始数据，键是文件开头部分文本行起始处的偏移量，值是一行数据的内容。

mapreduce框架每调读取一行数据，就调用一次map函数。

map函数的输出是键值对。 key: 单词  value: 1

框架在map处理完成后，将所有的KV缓存起来，进行分组，然后传递一个组，调用一次reduce方法

传递的组格式： key: 单词  value: [1,1,1,1, ...] 单词数列表

reduce函数对分组进行求和，输出键值对 key:单词 value:单词出现的总数

```

MR数据流如下：

![hadoop_mr](/files/hadoop_mr.png)

hadoop 把输入数据换分为等长的小数据发送大MapReduce，成为分片。

hadoop 为每个分片创建一个map任务，由map函数来分析每个分片的记录。

我们并行处理每个分片，且分片是小块数据，处理过程会有更好的负载均衡；

但，分片太小，管理分片总时间和map任务创建的总时间将决定作业的执行总时间。

理想的分片大小是HDFS的块的大小。

map任务的执行节点和输入数据的存储节点是同一个节点，hadoop的想念达到最佳。也是分片大小与块大小相同的原因，可以保证存储在单个节点上的数据量。

map任务把输出写在本地磁盘，而不是HDFS。

有序map的输出通过网络传输到reduce任务运行的节点，并在那里合并，然后传递到reduce函数中。

为了增加可靠性，reduce的输出通常存储在HDFS上。

reduce 的任务数，不是由输入的大小决定的，而是由单独指定的。

如果有多个reducer，map任务会低输出进行分区，为每个任务创建一个分区（partition）;

每个分区包括许多键，但每个键的记录都会在同一个分区中。

分区可以通过用户定义的partitioner来控制。但通常使用默认的分区方式，hash函数来分区。

hadoop允许用户定义一个combiner，运行在ap的输出上，其结果作为reduce函数的输入。

combiner是一个优化方法，hadoop不保证对某个map的输出记录是否调用该方法，调用与不调用该方法，不影响reduce的输出。

combiner可以帮助减少map与reduce之间的数据传输量，但不能代替reduce函数，因为reduce需要处理来自不同map给出的相同键记录。

combiner 其实是本地key的归并。

完整的数据流程如下：

![hadoop_mr_flow](/files/hadoop_mr_flow.png)

## hadoop流

hadoop提供一个API运行MapReduce，并允许使用java外的其他语言来编写map和reduce函数。

Hadoop使用Unix标准流作为hadoop和程序之间的接口，默认map输出流和reduce的输入流的key value格式通过制表符来分隔的。

hadoop命令不支持streaming函数，需要指定JAR文件流与jar选项。

例如：

```python
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper /bin/cat \
    -reducer /bin/wc
```

更详细的参考[hadoop streaming文档](http://hadoop.apache.org/docs/r1.2.1/streaming.html)

## hadoop 序列化

序列化是指将结构化对象转换为字节流以便通过网络进行传输或者写入持久存储的过程。

反序列化是指将字节流转换为一系列结构化对象的过程。

序列化用于分布式数据处理的两大作用：进行通信，永久存储。

hadoop节点间通信使用RPC实现的。

RPC协议使用序列化将消息编码为二进制流，此后，二进制流被反序列化为原始消息。

hadoop的序列化格式： Writables，它紧凑、快速

Writable接口是根据 DataIput 和 DataOutput实现简单、有效的序列化对象。

MR的任意key和value必须实现Writable接口

MR的任意key必须实现WritableComparable接口


## MapReduce的工作原理

0. 运行一个job，代码`obj.waitForCompletion()`，hadoop客户端运行一个RunJar进程

1. 向ResourceManger执行一个job

2. resourceManager 返回给客户端job相关资源提交路径（staging_dir）和为本job产生一个jobID

3. 客户端提交资源到给定的HDFS路径上

4. 向resourceManger汇报提交结果

5. ResourceManger将job加入任务队列。产生一个container，运行资源容器。并启动MR程序，MRAppMater。

6. 初始化job。

7. 从HDFS获取输入

8. 去ResourceManger申请资源

9. MRAppMater 启动 YarnChild 以运行MR程序

10. YarnChild获取job资源

11. 运行MR程序

![hadoop_mr_job](/files/hadoop_mr_job.png)

streaming 的任务和进程通信使用标准的输入输出。

![hadoop_mr_job](/files/hadoop_mr_job_streaming.png)



## YARN 框架

YARN 是hadoop集群的资源管理系统。

不光是可以支持MapReduce程序，还是很通用的分布式解决方案。

![hadoop_yarn](/files/hadoop_yarn.png)

YARN 运行应用程序的流程：

![hadoop_yarn_run](/files/hadoop_yarn_run.png)


## shuffle

MAP 进程数的决定机制-split：

* Map task的并发数，由切片的数量决定的，有多少切片就启动多少map task

* 切片是逻辑概念，指的是文件中数据的偏移量范围

* 切片具体大小应该可以根据处理文件的大小来调整


map输出数据到reduce直接的处理过程：

![hadoop_shuffle](/files/hadoop_shuffle.png)

每个map有一个环形内存缓冲区，用于存储任务的输出。默认100M，可以修改io.sort.mb属性。

一旦达到法旨0.8（io.sort.spill.percent），一个后台进程把内容写到磁盘指定的目录map.local.dir下新建一个溢出文件

写磁盘前，要partition sort。 如果有combiner，combine排序后数据

等最后记录写完，合并全部溢出写文件为一个分区且排序的文件。

reduce通过http方式获得输出文件的分区

TaskTracker为分区文件运行Reduce任务。复制阶段把map输出复制到reducer的内存或者磁盘。一个map任务完成，reduce就开始复制输出。

排序阶段合并map输出，然后再进行reduce阶段。



















