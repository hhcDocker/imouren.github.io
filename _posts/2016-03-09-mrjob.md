---
layout: post
title:  "使用python mrjob做mapreduce"
date:   2016-03-09 09:05:31
categories: python mrjob
tags: python mrjob
---

* content
{:toc}


## 安装mrjob
{% highlight python %}
pip install mrjob
{% endhighlight %}

## 第一个例子
{% highlight python %}
from mrjob.job import MRJob


class MRWordFrequencyCount(MRJob):

    def mapper(self, _, line):
        yield "chars", len(line)
        yield "words", len(line.split())
        yield "lines", 1

    def reducer(self, key, values):
        yield key, sum(values)


if __name__ == '__main__':
    MRWordFrequencyCount.run()

{% endhighlight %}

运行

{% highlight python %}
python word_count.py my_file.txt
{% endhighlight %}

结果

{% highlight python %}
"chars" 3654
"lines" 123
"words" 417
{% endhighlight %}

## 多个步骤的例子

{% highlight python %}
from mrjob.job import MRJob
from mrjob.step import MRStep
import re

WORD_RE = re.compile(r"[\w']+")


class MRMostUsedWord(MRJob):

    def steps(self):
        return [
            MRStep(mapper=self.mapper_get_words,
                   combiner=self.combiner_count_words,
                   reducer=self.reducer_count_words),
            MRStep(reducer=self.reducer_find_max_word)
        ]

    def mapper_get_words(self, _, line):
        # yield each word in the line
        for word in WORD_RE.findall(line):
            yield (word.lower(), 1)

    def combiner_count_words(self, word, counts):
        # optimization: sum the words we've seen so far
        yield (word, sum(counts))

    def reducer_count_words(self, word, counts):
        # send all (num_occurrences, word) pairs to the same reducer.
        # num_occurrences is so we can easily use Python's max() function.
        yield None, (sum(counts), word)

    # discard the key; it is just None
    def reducer_find_max_word(self, _, word_count_pairs):
        # each item of word_count_pairs is (count, word),
        # so yielding one results in key=counts, value=word
        yield max(word_count_pairs)


if __name__ == '__main__':
    MRMostUsedWord.run()
{% endhighlight %}

## 常用参数

`-q` 可以禁止输出debug信息

{% highlight python %}
$ python mr_most_used_word.py README.txt -q
"mrjob"
{% endhighlight %}


`> /dev/null` 可以禁止结果输出到终端


`--jobconf` hadoop运行选项

{% highlight python %}
--jobconf stream.non.zero.exit.is.failure=false
--jobconf mapreduce.job.maps=1
--jobconf mapreduce.job.reduces=1
{% endhighlight %}


`--verbose` 打印详细信息


## 问题与注意

### `lzo`文件的操作

{% highlight python %}
--jobconf stream.map.input.ignoreKey=true # 增加参数

# 在类中增加 HADOOP_INPUT_FORMAT
class MRIPCount(MRJob):
    HADOOP_INPUT_FORMAT = "com.hadoop.mapred.DeprecatedLzoTextInputFormat"

{% endhighlight %}

### mr引入其他包

将需要的包，进行压缩
{% highlight python %}
tar -C your-src-code -f your-src-code.tar.gz -z -c .
{% endhighlight %}

使用参数上传到hadoop cluster，并声明环境变量

{% highlight python %}
--setup 'export PYTHONPATH=$PYTHONPATH:your-src-dir.tar.gz#/'
{% endhighlight %}

注意：本机测试环境如果是python2.7的环境，hadoop集群上是python2.6环境，那么python2.7的新特性不能用，比如`from collections import Counter`

需要安装第三方以来，参考 http://pythonhosted.org/mrjob/guides/setup-cookbook.html



